---
title: "CH11"
output: 
  prettydoc::html_pretty:
  theme: leonids
---
```{r include=FALSE}
knitr::opts_chunk$set(
  root_dir = 'C:/Users/HK/Desktop/GitHub/Graduate/Bayesian'
)
library(rjags)
```

# CH11. 베이지안 분위 회귀분석 (Bayesian Quantile Regression Analysis)  
  
### 11.1 분위 회귀모형 (Quantile Regression Model)  
```{r fig.align='center', fig.width=5, fig.height=4}
u <- seq(-3, 3, length = 100)
closs <- function(p, u) rho <- u*(p-1)*(u < 0) + u*p*(u >= 0) # Check-Loss

plot(u, closs(0.5, u), type = 'l')
lines(u, closs(0.1, u), lty = 2, col = 4)
lines(u, closs(0.9, u), lty = 3, col = 2)
legend(1.5, 0.8, lty = c(2, 1, 3), col = c(4, 1, 2), legend = c('p=0.1', 'p=0.5', 'p=0.9'))
# 0에서 미분가능하지 않다.
```
  
- 분위회귀모형은 정규분포, 분포의 대칭성, 등분산성 등을 가정하지 않으므로 평균회귀모형에 비하여 상대적으로 분포에 대한 가정이 매우 약하여 적용할 수 있는 자료의 범위가 넓다.  
- 이상점의 영향을 덜 받는 로버스트한 방법이다.  
  
  
### 11.3 분위 회귀모형의 베이지안 분석  
- $Y=x\beta_p+\epsilon, Q_p(\epsilon)=0$  
- 비대칭 라플라스 분포(ALD)를 가정하면 체크 손실함수의 최소화와 우도함수의 최대화가 동일해진다.  
- 베이지안 분위 회귀모형: $Y=x\beta_p+\epsilon, \epsilon ~ ALD(p)$  
  
  
### 11.4 JAGS  
- 잠재변수를 $W ~ Exp(\sigma^2), Z ~ N(0, 1)$로 정의한다.  
  
#### 1) 우도함수를 직접 지정하는 방법  
```{r}
modelString <- "
model
{
  for (i in 1:length(y)) {
    fd[i] <- p * (1 - p) * exp(-check[i])       # likelihood
    check[i] <- e[i] * (p - (1 - step(e[i])))   # check-loss (cf. step: 계단함수)
    e[i] <- y[i] - inprod(x[i,1:K], beta[1:K])
    
    # use 0-1 trick #
    Ones[i] ~ dbern(pi[i])
    pi[i] <- fd[i] / 10000
  }
  beta[1:K] ~ dmnorm(mu[], Tau[,])
}
"
writeLines(modelString, 'model-BQR.txt')
```

#### 2) Gibb Sampling
```{r}
modelString <- "
model{
  theta <- (1-2*p)/(p*(1-p))
  eta
}
"
# writeLines(modelString, 'model-BQR-latent.txt')
```
  
  
### 11.5 실제 자료 분석 : Boston Housing Data  
```{r}
# load data
boston <- read.table('Data/Boston_data.txt', header = T)
x <- as.matrix(boston[,-3])
x <- scale(x)
x <- cbind(rep(1, nrow(x)), x)
x <- data.matrix(x)
colnames(x)[1] <- 'intercept'
K <- ncol(x)
y <- boston[,3]
data.name <- 'boston'
```
```{r}
# initial values
lm.summary <- lm(y ~ x -1)
mu <- coef(lm.summary)
Tau <- solve(vcov(lm.summary))*0.01
Ones <- rep(1, length(y))
initsList <- list(beta = mu)
```
```{r}
# JAGS
nAdapt <- 1000 ; nUpdate <- 10000 ; nIter <- 30000 ; nChains <- 3
p.set <- seq(0.1, 0.9, length = 9)
beta.hat <- matrix(0, length(p.set), K)
beta.cl <- beta.cu <- matrix(0, length(p.set), K)

for (ip in 1:length(p.set)) {
  p <- p.set[ip]
  # for BQR
  dataList <- list(p = p, K = K, y = y, x = x, Ones = Ones, mu = mu, Tau = Tau)
  # for BQR-latent
  # dataList <- list(p = p, K = K, y = y, x = x, mu = mu, Tau = Tau, a0 = 0.1, b0 = 0.1)
  
  jagsModel <- jags.model('model-BQR.txt', data = dataList, inits = initsList,
                          n.chains = nChains, n.adapt = nAdapt)
  update(jagsModel, n.iter = nUpdate)
  codaSamples <- coda.samples(jagsModel, variable.names = c('beta'),
                              thin = 1, n.iter = nIter)
  mcmcSamples <- as.matrix(codaSamples)
  
  beta.hat[ip, 1:K] <- quantile(mcmcSamples[,1:K], 0.5)
  beta.cu[ip, 1:K] <- quantile(mcmcSamples[,1:K], 0.025)
  beta.cl[ip, 1:K] <- quantile(mcmcSamples[,1:K], 0.975)
}
```
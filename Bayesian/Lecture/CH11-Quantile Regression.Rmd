---
title: "CH11"
output: 
  prettydoc::html_pretty:
  theme: leonids
---
```{r include=FALSE}
knitr::opts_chunk$set(
  root_dir = 'C:/Users/HK/Desktop/GitHub/Graduate/Bayesian'
)
library(rjags)
```

# CH11. 베이지안 분위 회귀분석 (Bayesian Quantile Regression Analysis)  
  
### 11.1 분위 회귀모형 (Quantile Regression Model)  
```{r fig.align='center', fig.width=6, fig.height=4}
u <- seq(-3, 3, length = 100)
closs <- function(p, u) rho <- u*(p-1)*(u < 0) + u*p*(u >= 0) # Check-Loss

plot(u, closs(0.5, u), type = 'l', ylab = 'check loss')
lines(u, closs(0.1, u), lty = 2, col = 4)
lines(u, closs(0.9, u), lty = 3, col = 2)
legend(1.5, 0.8, lty = c(2, 1, 3), col = c(4, 1, 2), legend = c('p=0.1', 'p=0.5', 'p=0.9'))
# 0에서 미분가능하지 않다.
```
  
- 분위회귀모형은 정규분포, 분포의 대칭성, 등분산성 등을 가정하지 않으므로 평균회귀모형에 비하여 상대적으로 분포에 대한 가정이 매우 약하여 적용할 수 있는 자료의 범위가 넓다.  
- 이상점의 영향을 덜 받는 로버스트한 방법이다.  
  
  
### 11.3 분위 회귀모형의 베이지안 분석  
- $Y=x\beta_p+\epsilon, Q_p(\epsilon)=0$  
- 비대칭 라플라스 분포(ALD)를 가정하면 체크 손실함수의 최소화와 우도함수의 최대화가 동일해진다.  
- 베이지안 분위 회귀모형: $Y=x\beta_p+\epsilon, \epsilon ~ ALD(p)$  
  
  
### 11.4 JAGS  
- 잠재변수를 $W ~ Exp(\sigma^2), Z ~ N(0, 1)$로 정의한다.  
  
#### 1) 우도함수를 직접 지정하는 방법  
```{r}
modelString <- "
model
{
  for (i in 1:length(y)) {
    fd[i] <- p*(1-p)*exp(-check[i])       # likelihood
    check[i] <- e[i]*(p-(1-step(e[i])))   # check-loss (cf. step: 계단함수)
    e[i] <- y[i] - inprod(x[i,1:K], beta[1:K])
    
    # use 0-1 trick #
    Ones[i] ~ dbern(pi[i])
    pi[i] <- fd[i] / 10000
  }
  beta[1:K] ~ dmnorm(mu[], Tau[,])
}
"
writeLines(modelString, 'model-BQR.txt')
```

#### 2) Gibb Sampling
```{r}
modelString <- "
model
{
  theta <- (1-2*p)/(p*(1-p))
  eta <- 2/(p*(1-p))
  
  for (i in 1:length(y)) {
    w[i] ~ dexp(sigsq)
    y[i] ~ dnorm(mu.y[i], tau.y[i])
    mu.y[i] <- inprod(x[i,1:K], beta[1:k]) + theta*w[i]
    tau.y[i] <- 1/(eta*w[i]*sigsq)
  }
  
  inv.sigsq ~ dgamma(a0, b0)
  sigsq <- 1/sqrt(inv.sigsq)
  
  beta[1:K] ~ dmnorm(mu[], Tau[])
}
"
writeLines(modelString, 'model-BQR-latent.txt')
```
  
  
### 11.5 실제 자료 분석 : Boston Housing Data  
  
- 선형 회귀모형을 적합시켜 얻은 계수 추정치를 정규 사전분포의 평균으로 사용하고 추정치의 분산에 100을 곱하여 사전분산으로 사용한다.  
- 모수 $\sigma^2$의 사전분포로 IG(0.1, 0.1)을 가정한다.  
- 0-1 기법을 사용하여 우도함수를 직접 지정하기 위하여 베르누이 분포를 따르는 가상 자료 Ones를 dataList에서 제공한다.  
- 분위수 p=0.1, ..., 0.9에 대하여 분위 회귀모형 회귀계수 추정치를 구한 후 각 설명변수에 대해 분위수에 따른 추정치의 변화를 확인한다.  
  
```{r}
# load data
boston <- read.table('C:/Users/HK/Desktop/GitHub/Graduate/Bayesian/Data/Boston_data.txt', header = T)
x <- as.matrix(boston[,-3])
x <- scale(x)
x <- cbind(rep(1, nrow(x)), x)
x <- data.matrix(x)
colnames(x)[1] <- 'intercept'
K <- ncol(x)
y <- boston[,3]
data.name <- 'boston'
```
```{r}
# initial values
lm.summary <- lm(y ~ x -1)
mu <- coef(lm.summary)
Tau <- solve(vcov(lm.summary))*0.01
Ones <- rep(1, length(y))
initsList <- list(beta = mu)
```
```{r}
# JAGS
nAdapt <- 1000 ; nUpdate <- 10000 ; nIter <- 30000 ; nChains <- 3
p.set <- seq(0.1, 0.9, length = 9)
beta.hat <- matrix(0, length(p.set), K)
beta.cl <- beta.cu <- matrix(0, length(p.set), K)

for (ip in 1:length(p.set)) {
  p <- p.set[ip]
  # for BQR
  dataList <- list(p = p, K = K, y = y, x = x, Ones = Ones, mu = mu, Tau = Tau)
  # for BQR-latent
  # dataList <- list(p = p, K = K, y = y, x = x, mu = mu, Tau = Tau, a0 = 0.1, b0 = 0.1)
  
  jagsModel <- jags.model('model-BQR.txt', data = dataList, inits = initsList,
                          n.chains = nChains, n.adapt = nAdapt)
  update(jagsModel, n.iter = nUpdate)
  codaSamples <- coda.samples(jagsModel, variable.names = c('beta'),
                              thin = 1, n.iter = nIter)
  mcmcSamples <- as.matrix(codaSamples)
  
  beta.hat[ip, 1:K] <- quantile(mcmcSamples[,1:K], 0.5)
  beta.cu[ip, 1:K] <- quantile(mcmcSamples[,1:K], 0.025)
  beta.cl[ip, 1:K] <- quantile(mcmcSamples[,1:K], 0.975)
  
  par(mfrow = c(2, 3))
  for (k in 2:7) {
    plot(p.set, beta.hat[,k], type = 'l', 
         ylim = c(min(beta.cl[,k]), max(beta.cu[,k])), 
         xlab = 'p', ylab = colnames(x)[k])
    lines(p.set, beta.cl[,k], col = 3)
    lines(p.set, beta.cu[,k], col = 3)
    abline(h = 0)
  }
}
```
